<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Machine Learning : ROC and AUC | 记录学习点滴</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/very-simple.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><!-- include the sidebar--><!-- include ./includes/sidebar.jade--><!-- Blog title and subtitle--><header><div class="container header"><a id="logo" href="/." class="title">记录学习点滴</a><span class="subtitle"></span><label id="toggle-menu" for="menu" onclick><i class="fa fa-bars"></i></label></div></header><!-- use checkbox hack for toggle nav-bar on small screens--><input id="menu" type="checkbox"><!-- Navigation Links--><nav id="nav"><div class="container"><a href="/" class="sidebar-nav-item active">Home</a><a href="/archives" class="sidebar-nav-item">Archives</a><a href="/categories" class="sidebar-nav-item">Categories</a></div></nav><div id="header-margin-bar"></div><!-- gallery that comes before the header--><div class="wrapper"><div class="container post-header"><h1>Machine Learning : ROC and AUC</h1></div></div><div class="wrapper"><div class="container meta"><div class="post-time">2019-07-07</div></div></div><article><div class="container post"><font size="3">机器学习之ROC和AUC</font>

<p><font size="4">1.ROC：<font size="4"><br>在机器学习理论中，可用ROC曲线来分析二元分类模型。在二分类问题中，数据的标签通常用（0/1）来表示，在模型训练完成后进行测试时，会对测试集的每个样本计算一个介于 0~1 之间的概率，表征模型认为该样本为阳性的概率。我们可以选定一个阈值，将模型计算出的概率进行二值化，比如选定阈值等于0.5，那么当模型输出的值大于等于 0.5 时，我们就认为模型将该样本预测为阳性，也就是标签为 1，反之亦然。选定的阈值不同，模型预测的结果也会相应地改变。二元分类模型的单个样本预测有四种结果：<br>真阳性（TP）：判断为阳性，实际也是阳性。<br>伪阳性（FP）：判断为阳性，实际却是阴性。<br>真阴性（TN）：判断为阴性，实际也是阴性。<br>伪阴性（FN）：判断为阴性，实际却是阳性。<br>这四种结果可以画成 2×2 的混淆矩阵：<br><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/1.png" alt="waitting"><br>有了混淆矩阵，就可以定义ROC曲线了。ROC曲线将假阳性率（FPR）定义为X轴，真阳性率（TPR）定义为 Y 轴。其中：<br>TPR：在所有实际为阳性的样本中，被正确地判断为阳性的样本比率。<br>TPR=TP/(TP+FN)<br>FPR：在所有实际为阴性的样本中，被错误地判断为阳性的样本比率。<br>FPR=FP/(FP+TN)<br>给定一个二分类模型和它的阈值，就可以根据所有测试集样本点的真实值和预测值计算出一个(X=FPR,Y=TPR)坐标点，使用单点绘图方法即可得到 ROC 曲线。 </font></font></p>
<p><font size="4">2.AUC：<font size="4"><br>AUC 的全称是 Area under the Curve of ROC，也就是 ROC 曲线下方的面积。在机器学习领域，经常用 AUC 值来评价一个二分类模型的训练效果。<br>AUC 被定义为 ROC 曲线下的面积，显然这个面积的数值不会大于 1。在检验模型时，AUC 值越大的模型，正确率越高。<br>例如：已经得出一系列样本被划分为正类的概率，按照大小排序，下图是一个示例，图中共有 20 个测试样本，“Class”一栏表示每个测试样本真正的标签（P 表示正样本，N 表示负样本），“Score”表示每个测试样本属于正样本的概率。<br><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/2.png" alt="waitting"><br>接下来，从高到低依次将“Score”值作为阈值 threshold，当测试样本属于正样本的概率大于或等于这个 threshold 时，认为它为正样本，否则为负样本。举例来说，对于图中第 4 个样本，其“Score”值为 0.6，那么样本 1、2、3、4 都被认为是正样本，因为它们的“Score”值都大于等于 0.6，而其他样本则都认为是负样本。每次选取一个不同的 threshold，就可以得到一组 FPR 和 TPR，即 ROC 曲线上的一点。这样一来，一共得到了 20 组 FPR 和 TPR 的值，将它们画成 ROC 曲线的结果如下图：<br><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/3.png" alt="waitting"><br>AUC(Area under Curve)：ROC 曲线下的面积，介于 0.1 和 1 之间。AUC 作为数值可以直观地评价分类器的好坏，值越大越好。 </font></font></p>
<p><font size="4">3.sklearn计算ROC<font size="4"><br>sklearn给出了一个计算ROC的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = np.array([1, 1, 2, 2])</span><br><span class="line">scores = np.array([0.1, 0.4, 0.35, 0.8])</span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)</span><br></pre></td></tr></table></figure></font></font></p>
<p>通过计算，得到的结果（TPR, FPR, 截断点）为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fpr = array([ 0. ,  0.5,  0.5,  1. ])</span><br><span class="line">tpr = array([ 0.5,  0.5,  1. ,  1. ])</span><br><span class="line">thresholds = array([ 0.8 ,  0.4 ,  0.35,  0.1 ])#截断点</span><br></pre></td></tr></table></figure></p>
<p>将结果中的FPR与TPR画到二维坐标中，得到的ROC曲线如下（蓝色线条表示），ROC曲线的面积用AUC表示（淡黄色阴影部分）。<br><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/4.png" alt="waitting"></p>
<p><font size="4">4.详细的计算过程<font size="4"><br>上例给出的数据如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = np.array([1, 1, 2, 2])</span><br><span class="line">scores = np.array([0.1, 0.4, 0.35, 0.8])</span><br></pre></td></tr></table></figure></font></font></p>
<p>用这个数据，计算TPR，FPR的过程是怎么样的呢？<br>(1)分析数据<br>y是一个一维数组（样本的真实分类）。数组值表示类别（一共有两类，1和2）。我们假设y中的1表示反例，2表示正例。即将y重写为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_true = [0, 0, 1, 1]</span><br></pre></td></tr></table></figure></p>
<p>score即各个样本属于正例的概率。</p>
<p>(2)针对score，将数据排序<br><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/5.png" alt="waitting"></p>
<p>(3)将截断点依次取为score值<br>将截断点依次取值为0.1,0.35,0.4,0.8时，计算TPR和FPR的结果。</p>
<p>1)截断点为0.1<br>说明只要score&gt;=0.1，它的预测类别就是正例。<br>此时，因为4个样本的score都大于等于0.1，所以，所有样本的预测类别都为P。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = [0.1, 0.4, 0.35, 0.8]</span><br><span class="line">y_true = [0, 0, 1, 1] </span><br><span class="line">y_pred = [1, 1, 1, 1]</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/6.png" alt="waitting"><br>TPR = TP/(TP+FN) = 1<br>FPR = FP/(TN+FP) = 1</p>
<p>2)截断点为0.35<br>说明只要score&gt;=0.35，它的预测类别就是P。<br>此时，因为4个样本的score有3个大于等于0.35。所以，所有样本的预测类有3个为P（2个预测正确，1一个预测错误）；1个样本被预测为N（预测正确）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = [0.1, 0.4, 0.35, 0.8]</span><br><span class="line">y_true = [0, 0, 1, 1] </span><br><span class="line">y_pred = [0, 1, 1, 1]</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/7.png" alt="waitting"><br>TPR = TP/(TP+FN) = 1<br>FPR = FP/(TN+FP) = 0.5</p>
<p>3)截断点为0.4<br>说明只要score&gt;=0.4，它的预测类别就是P。<br>此时，因为4个样本的score有2个大于等于0.4。所以，所有样本的预测类有2个为P（1个预测正确，1一个预测错误）；2个样本被预测为N（1个预测正确，1一个预测错误）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = [0.1, 0.4, 0.35, 0.8]</span><br><span class="line">y_true = [0, 0, 1, 1] </span><br><span class="line">y_pred = [0, 1, 0, 1]</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/8.png" alt="waitting"><br>TPR = TP/(TP+FN) = 0.5<br>FPR = FP/(TN+FP) = 0.5</p>
<p>4)截断点为0.8<br>说明只要score&gt;=0.8，它的预测类别就是P。所以，所有样本的预测类有1个为P（1个预测正确）；3个样本被预测为N（2个预测正确，1一个预测错误）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = [0.1, 0.4, 0.35, 0.8]</span><br><span class="line">y_true = [0, 0, 1, 1] </span><br><span class="line">y_pred = [0, 0, 0, 1]</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/YuemingBi/comment-repo/raw/master/image/Machine Learing ROC and AUC/9.png" alt="waitting"><br>TPR = TP/(TP+FN) = 0.5<br>FPR = FP/(TN+FP) = 0</p>
</div><!-- comment system--><div class="container"><hr></div></article><footer id="footer"><div class="container"><div class="bar"><div class="social"><a href="/atom.xml" target="_blank"><i class="fa fa-rss"></i></a></div><div class="footer">© 2019 <a href="/" rel="nofollow">YuemingBi</a>. Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a>. Theme <a target="_blank" href="https://github.com/lotabout/very-simple">very-simple</a>.</div></div></div></footer><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});
</script></body></html>